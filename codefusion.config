Intention: The user intends to debug the video uploading process by checking the status of the file using the Gemini API, ensuring it is in an 'ACTIVE' state before attempting to use it for further processing. The user may also want to see how long the video takes to be in ACTIVE status.

Summary: The user encountered a 500 Internal Server Error related to google.genai with a FAILED_PRECONDITION error. The user then consulted the Gemini API documentation, specifically focusing on verifying file upload status and checking the state of the file in the API. The user is likely debugging a video upload and wants to ensure the file is in an ACTIVE state before processing.

Segments: 
No speech detected.

Screen Events: ['User is viewing the process_video.py file in CodeFusion.', 'The code includes a VideoSummary class, environment variable loading using load_dotenv(), Gemini API key retrieval, and video uploading/processing functions.']
Visited Files: ['process_video.py']
Visited URLs: []

No speech detected.

Screen Events: ['User is still viewing the process_video.py file in CodeFusion.', 'The code includes a Gemini API key retrieval using os.getenv.', 'The code includes functions for video uploading and processing.']
Visited Files: ['process_video.py']
Visited URLs: []

No speech detected.

Screen Events: ['User switches to the Postman application.', 'Postman shows a GET request to http://127.0.0.1:5002/respond resulting in a 500 Internal Server Error.', 'Error message indicates a google.genai.errors.ClientError: 400 FAILED_PRECONDITION.']
Visited Files: ['Postman']
Visited URLs: ['http://127.0.0.1:5002/respond']

No speech detected.

Screen Events: ['User is still viewing the Postman application.', 'The error message in Postman says: The file 1lqkhbz7t06g is not in an ACTIVE state and usage is not allowed.']
Visited Files: ['Postman']
Visited URLs: ['http://127.0.0.1:5002/respond']

No speech detected.

Screen Events: ['User switches to the Google AI for Developers website to view Gemini API documentation.', 'User is looking at the "Verify file upload and check state" section.']
Visited Files: []
Visited URLs: ['https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video']

No speech detected.

Screen Events: ['User continues viewing the Google AI for Developers website to view Gemini API documentation.', 'The user is looking at a note describing the file state in the File API (ACTIVE, PROCESSING or FAILED).']
Visited Files: []
Visited URLs: ['https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video']

No speech detected.

Screen Events: ['User continues viewing the Google AI for Developers website to view Gemini API documentation.', 'The user is looking at the python code on how to check if the file is ready for use.']
Visited Files: []
Visited URLs: ['https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video']

No speech detected.

Screen Events: ['User switches back to CodeFusion.']
Visited Files: []
Visited URLs: []


Docs: 
Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
To ask questions about time-stamped locations, use the format `MM:SS`, where
the first two digits represent minutes and the last two digits represent
seconds.

For best results:

* Use one video per prompt.
* If using a single video, place the text prompt after the video.

### Upload a video file using the File API

**Note:** The File API lets you store up to 20 GB of files per project, with a
per-file maximum size of 2 GB. Files are stored for 48 hours. They can be
accessed in that period with your API key, but they cannot be downloaded
using any API. It is available at no cost in all regions where the Gemini
API is available.

The File API accepts video file formats directly. This example uses the
short NASA film
["Jupiter's Great Red Spot Shrinks and Grows"](https://www.youtube.com/watch?v=JDi4IdtvDVE0).
Credit: Goddard Space Flight Center (GSFC)/David Ladd (2018).

"Jupiter's Great Red Spot Shrinks and Grows" is in the public domain and does
not show identifiable people.
([NASA image and media usage guidelines.](https://www.nasa.gov/nasa-brand-center/images-and-media/))

Start by retrieving the short video:

```
wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4
```

Upload the video using the File API and print the URI.

```
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

print("Uploading file...")
video_file = client.files.upload(path="GreatRedSpot.mp4")
print(f"Completed upload: {video_file.uri}")

```
### Verify file upload and check state

Verify the API has successfully received the files by calling the
[`files.get`](https://ai.google.dev/api/rest/v1beta/files/get) method.

**Note:** Video files have a `State` field in the File API. When a video is
uploaded, it will be in the `PROCESSING` state until it is ready for inference.
**Only `ACTIVE` files can be used for model inference.**
```
import time


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
```
### Verify file upload and check state

Verify the API has successfully received the files by calling the
[`files.get`](https://ai.google.dev/api/rest/v1beta/files/get) method.

**Note:** Video files have a `State` field in the File API. When a video is
uploaded, it will be in the `PROCESSING` state until it is ready for inference.
**Only `ACTIVE` files can be used for model inference.**
```
import time

# Check whether the file is ready to be used.
while video_file.state.name == "PROCESSING":
    print('.', end='')
    time.sleep(1)
    video_file = client.files.get(name=video_file.name)

if video_file.state.name == "FAILED":
  raise ValueError(video_file.state.name)

print('Done')

```
### Prompt with a video and text

Once the uploaded video is in the `ACTIVE` state, you can make `GenerateContent`
requests that specify the File API URI for that video. Select the generative
model and provide it with the uploaded video and a text prompt.

```
from IPython.display import Markdown

# Pass the video file reference like any other media part.
response = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[
        video_file,
        "Summarize this video. Then create a quiz with answer key "
        "based on the information in the video."])

# Print the response, rendering any Markdown
Markdown(response.text)

```
### Refer to timestamps in the content

You can use timestamps of the form `HH:MM:SS` to refer to specific moments in the
video.

```
prompt = "What are the examples given at 01:05 and 01:19 supposed to show us?"

response = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[video_file, prompt])

print(response.text)

```
### Transcribe video and provide visual descriptions


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
```

Delete files
------------

Files uploaded using the File API are automatically deleted after 2 days. You
can also manually delete them using
[`files.delete`](/api/files#method:-files.delete).

```
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

# Upload a file
poem_file = client.files.upload(path="poem.txt")

# Files will auto-delete after a period.
print(poem_file.expiration_time)

# Or they can be deleted explicitly.
dr = client.files.delete(name=poem_file.name)

try:
  client.models.generate_content(
      model="gemini-2.0-flash-exp",
      contents=['Finish this poem:', poem_file])
except genai.errors.ClientError as e:
  print(e.code)  # 403
  print(e.status)  # PERMISSION_DENIED
  print(e.message)  # You do not have permission to access the File .. or it may not exist.

```

What's next
-----------

This guide shows how to upload image and video files using the File API and
then generate text outputs from image and video inputs. To learn more,
see the following resources:

* [File prompting strategies](/gemini-api/docs/file-prompting-strategies): The
  Gemini API supports prompting with text, image, audio, and video data, also
  known as multimodal prompting.
* [System instructions](/gemini-api/docs/system-instructions): System
  instructions let you steer the behavior of the model based on your specific
  needs and use cases.
* [Safety guidance](/gemini-api/docs/safety-guidance): Sometimes generative AI
  models produce unexpected outputs, such as outputs that are inaccurate,
  biased, or offensive. Post-processing and human evaluation are essential to
  limit the risk of harm from such outputs.

Was this helpful?
Send feedback


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
# Print the response, rendering any Markdown
Markdown(response.text)

```
### Refer to timestamps in the content

You can use timestamps of the form `HH:MM:SS` to refer to specific moments in the
video.

```
prompt = "What are the examples given at 01:05 and 01:19 supposed to show us?"

response = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[video_file, prompt])

print(response.text)

```
### Transcribe video and provide visual descriptions

The Gemini models can transcribe and provide visual descriptions of video content
by processing both the audio track and visual frames.
For visual descriptions, the model samples the video at a rate of **1 frame
per second**. This sampling rate may affect the level of detail in the
descriptions, particularly for videos with rapidly changing visuals.

```
prompt = (
    "Transcribe the audio from this video, giving timestamps for "
    "salient events in the video. Also provide visual descriptions.")

response = client.models.generate_content(
    model="gemini-1.5-pro",
    contents=[video_file, prompt])

print(response.text)

```

List files
----------

You can list all files uploaded using the File API and their URIs using
[`files.list`](/api/files#method:-files.list).

```
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

print('My files:')
for f in client.files.list():
  print(" ", f'{f.name}: {f.uri}')

```

Delete files
------------

Files uploaded using the File API are automatically deleted after 2 days. You
can also manually delete them using
[`files.delete`](/api/files#method:-files.delete).

```
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

# Upload a file
poem_file = client.files.upload(path="poem.txt")

# Files will auto-delete after a period.
print(poem_file.expiration_time)

# Or they can be deleted explicitly.
dr = client.files.delete(name=poem_file.name)


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video
The page at `https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video` is likely a part of the documentation for Google's Gemini API, specifically focusing on the vision capabilities. The section titled "prompting-video" suggests that it covers how to use the API to work with video data in the context of vision tasks, using Python as the programming language. It may include examples and instructions on how to prompt the API to process or analyze video content.

Chunk Content:
[Sign in](https://ai.google.dev/_d/signin?continue=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Fvision%2Flang%2Fpython%23prompting-video&prompt=select_account)


[![Google AI for Developers](https://ai.google.dev/_static/googledevai/images/lockup-new.svg)](/)

* Models
  
  + More
* Solutions
  
  + More
* Code assistance
  
  + More
* Showcase
  
  + More
* Community
  
  + More

* Gemini
* [About](https://deepmind.google/gemini)
* [Docs](/gemini-api/docs)
* [API reference](/api)
* [Pricing](/pricing)
* Gemma
* [About](/gemma)
* [Docs](/gemma/docs)

* Build with Gemini
* [Gemini API](/gemini-api/docs)
* [Google AI Studio](https://aistudio.google.com)
* Customize Gemma open models
* [Gemma open models](/gemma)
* [Multi-framework with Keras](https://keras.io/keras_3/)
* [Fine-tune in Colab](https://colab.sandbox.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb)
* Run on-device
* [Google AI Edge](/edge)
* [Gemini Nano on Android](https://developer.android.com/ai/gemini-nano)
* [Chrome built-in web APIs](https://developer.chrome.com/docs/ai/built-in)
* Build responsibly
* [Responsible GenAI Toolkit](/responsible)
* [Secure AI Framework](https://saif.google)

* [Android Studio](https://developer.android.com/gemini-in-android)
* [Chrome DevTools](https://developer.chrome.com/docs/devtools/console/understand-messages)
* [Colab](https://colab.google)
* [Firebase](https://firebase.google.com/products/generative-ai)
* [Google Cloud](https://cloud.google.com/products/gemini/code-assist)
* [JetBrains](https://plugins.jetbrains.com/plugin/8079-google-cloud-code)
* [Jules](https://labs.google.com/jules/home)
* [Project IDX](https://developers.google.com/idx/guides/code-with-gemini-in-idx)
* [VS Code](https://marketplace.visualstudio.com/items?itemName=GoogleCloudTools.cloudcode)

* [Gemini Showcase](/showcase)
* [Gemini API Developer Competition](/competition)


URL: https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
Gemini models are able to process images and videos, enabling many frontier
developer use cases that would have historically required domain specific models.
Some of Gemini's vision capabilities include the ability to:

* Caption and answer questions about images
* Transcribe and reason over PDFs, including up to 2 million tokens
* Describe, segment, and extract information from videos up to 90 minutes long
* Detect objects in an image and return bounding box coordinates for them

Gemini was built to be multimodal from the ground up and we continue to push the
frontier of what is possible.

Image input
-----------

For total image payload size less than 20MB, we recommend either uploading
base64 encoded images or directly uploading locally stored image files.

### Working with local images

If you are using the Python imaging library ([Pillow](https://pypi.org/project/pillow/)), you can use PIL image objects too.

```
from google import genai
from google.genai import types

import PIL.Image

image = PIL.Image.open('/path/to/image.png')

client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=["What is this image?", image])

print(response.text)

```
### Base64 encoded images

You can upload public image URLs by encoding them as Base64 payloads. The
following code example shows how to do this using only standard library tools:

```
from google import genai
from google.genai import types

import requests

image_path = "https://goo.gle/instrument-img"
image = requests.get(image_path)

client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=["What is this image?",
              types.Part.from_bytes(image.content, "image/jpeg")])

print(response.text)

```
### Multiple images


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
To explore more detailed examples of generating bounding box coordinates and
visualizing them on images, we encourage you to review our [Object Detection cookbook example](https://github.com/google-gemini/cookbook/blob/main/examples/Object_detection.ipynb).

Prompting with video
--------------------

In this tutorial, you will upload a video using the File API and generate
content based on those images.

**Note:** The File API is required to upload video files, due to their size.
However, the File API is only available for Python, Node.js, Go, and REST.
### Technical details (video)

Gemini 1.5 Pro and Flash support up to approximately an hour of video data.

Video must be in one of the following video format MIME types:

* `video/mp4`
* `video/mpeg`
* `video/mov`
* `video/avi`
* `video/x-flv`
* `video/mpg`
* `video/webm`
* `video/wmv`
* `video/3gpp`

The File API service extracts image frames from videos at 1 frame per second
(FPS) and audio at 1Kbps, single channel, adding timestamps every second.
These rates are subject to change in the future for improvements in inference.

**Note:** The details of fast action sequences may be lost at the 1 FPS frame
sampling rate. Consider slowing down high-speed clips for improved inference
quality.

Individual frames are 258 tokens, and audio is 32 tokens per second. With
metadata, each second of video becomes ~300 tokens, which means a 1M context
window can fit slightly less than an hour of video.

To ask questions about time-stamped locations, use the format `MM:SS`, where
the first two digits represent minutes and the last two digits represent
seconds.

For best results:

* Use one video per prompt.
* If using a single video, place the text prompt after the video.

### Upload a video file using the File API


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
* Gemini
* [About](https://deepmind.google/gemini)
* [Docs](/gemini-api/docs)
* [API reference](/api)
* [Pricing](/pricing)
* Gemma
* [About](/gemma)
* [Docs](/gemma/docs)

* Build with Gemini
* [Gemini API](/gemini-api/docs)
* [Google AI Studio](https://aistudio.google.com)
* Customize Gemma open models
* [Gemma open models](/gemma)
* [Multi-framework with Keras](https://keras.io/keras_3/)
* [Fine-tune in Colab](https://colab.sandbox.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb)
* Run on-device
* [Google AI Edge](/edge)
* [Gemini Nano on Android](https://developer.android.com/ai/gemini-nano)
* [Chrome built-in web APIs](https://developer.chrome.com/docs/ai/built-in)
* Build responsibly
* [Responsible GenAI Toolkit](/responsible)
* [Secure AI Framework](https://saif.google)

* [Android Studio](https://developer.android.com/gemini-in-android)
* [Chrome DevTools](https://developer.chrome.com/docs/devtools/console/understand-messages)
* [Colab](https://colab.google)
* [Firebase](https://firebase.google.com/products/generative-ai)
* [Google Cloud](https://cloud.google.com/products/gemini/code-assist)
* [JetBrains](https://plugins.jetbrains.com/plugin/8079-google-cloud-code)
* [Jules](https://labs.google.com/jules/home)
* [Project IDX](https://developers.google.com/idx/guides/code-with-gemini-in-idx)
* [VS Code](https://marketplace.visualstudio.com/items?itemName=GoogleCloudTools.cloudcode)

* [Gemini Showcase](/showcase)
* [Gemini API Developer Competition](/competition)

* [Google AI Forum](https://discuss.ai.google.dev)
* [Gemini for Research](/gemini-api/docs/gemini-for-research)


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at `ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video` is likely part of the Google AI Gemini API documentation, specifically focused on the "Vision" component of the API. Since the URL includes `?lang=python`, it suggests that the documentation is tailored to Python developers. The section identified by `#prompting-video` is probably about how to use the Vision capabilities of the Gemini API to process or analyze video content. It may provide information or examples on how to prompt the API to perform specific tasks related to video, such as video analysis or recognition, using Python.

Chunk Content:
{"errors":{"query":{"url":["ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video is an invalid URL"]}}}


URL: ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
[Sign in](https://ai.google.dev/_d/signin?continue=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Fvision%3Flang%3Dpython%23prompting-video&prompt=select_account)

[Gemini API docs](https://ai.google.dev/gemini-api/docs)

[API Reference](https://ai.google.dev/api)

[SDKs](https://ai.google.dev/gemini-api/docs/sdks)

[Pricing](https://ai.google.dev/gemini-api/docs/pricing)

[Cookbook](https://github.com/google-gemini/cookbook)

More


[![Gemini API](https://ai.google.dev/_static/googledevai/images/lockup-new.svg)](/)

* [Models](/gemini-api/docs)
  + More
  + [Gemini API docs](/gemini-api/docs)
  + [API Reference](/api)
  + [SDKs](/gemini-api/docs/sdks)
  + [Pricing](/gemini-api/docs/pricing)
  + [Cookbook](https://github.com/google-gemini/cookbook)
* Solutions
  
  + More
* Code assistance
  
  + More
* Showcase
  
  + More
* Community
  
  + More


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
* [Gemini Showcase](/showcase)
* [Gemini API Developer Competition](/competition)

* [Google AI Forum](https://discuss.ai.google.dev)
* [Gemini for Research](/gemini-api/docs/gemini-for-research)


* On this page
* [Image input](#image-input)
  + [Working with local images](#local-images)
  + [Base64 encoded images](#base64-encoded)
  + [Multiple images](#multiple-images)
  + [Large image payloads](#large-images)
  + [OpenAI Compatibility](#openai-compat)
* [Prompting with images](#prompting-images)
  + [Technical details (images)](#technical-details-image)
* [Capabilities](#capabilities)
  + [Get a bounding box for an object](#bbox)
* [Prompting with video](#prompting-video)
  + [Technical details (video)](#technical-details-video)
  + [Upload a video file using the File API](#upload-video)
  + [Verify file upload and check state](#verify-file)
  + [Prompt with a video and text](#prompt-video)
  + [Refer to timestamps in the content](#refer-timestamps)
  + [Transcribe video and provide visual descriptions](#transcribe-video)
* [List files](#list-files)
* [Delete files](#delete-files)
* [What's next](#whats-next)


Gemini 2.0 Flash is now production ready! [Learn more](https://developers.googleblog.com/en/gemini-2-family-expands/)

* [Home](https://ai.google.dev/)
* [Gemini API](https://ai.google.dev/gemini-api)
* [Models](https://ai.google.dev/gemini-api/docs)

Was this helpful?

Send feedback

Explore vision capabilities with the Gemini API
===============================================


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
Explore vision capabilities with the Gemini API  |  Google AI for Developers

[Skip to main content](#main-content)

ai.google.dev uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. [Learn more](https://policies.google.com/technologies/cookies?hl=en).

Hide

[![Gemini API](https://ai.google.dev/_static/googledevai/images/lockup-new.svg)](/)


[Models](https://ai.google.dev/gemini-api/docs)

* Gemini
* [About](https://deepmind.google/gemini)
* [Docs](https://ai.google.dev/gemini-api/docs)
* [API reference](https://ai.google.dev/api)
* [Pricing](https://ai.google.dev/pricing)

* Gemma
* [About](https://ai.google.dev/gemma)
* [Docs](https://ai.google.dev/gemma/docs)


Solutions

* Build with Gemini
* [Gemini API](https://ai.google.dev/gemini-api/docs)
* [Google AI Studio](https://aistudio.google.com)

* Customize Gemma open models
* [Gemma open models](https://ai.google.dev/gemma)
* [Multi-framework with Keras](https://keras.io/keras_3/)
* [Fine-tune in Colab](https://colab.sandbox.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb)

* Run on-device
* [Google AI Edge](https://ai.google.dev/edge)
* [Gemini Nano on Android](https://developer.android.com/ai/gemini-nano)
* [Chrome built-in web APIs](https://developer.chrome.com/docs/ai/built-in)

* Build responsibly
* [Responsible GenAI Toolkit](https://ai.google.dev/responsible)
* [Secure AI Framework](https://saif.google)


Code assistance


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
Gemini 2.0 Flash is now production ready! [Learn more](https://developers.googleblog.com/en/gemini-2-family-expands/)

* [Home](https://ai.google.dev/)
* [Gemini API](https://ai.google.dev/gemini-api)
* [Models](https://ai.google.dev/gemini-api/docs)

Was this helpful?

Send feedback

Explore vision capabilities with the Gemini API
===============================================


* On this page
* [Image input](#image-input)
  + [Working with local images](#local-images)
  + [Base64 encoded images](#base64-encoded)
  + [Multiple images](#multiple-images)
  + [Large image payloads](#large-images)
  + [OpenAI Compatibility](#openai-compat)
* [Prompting with images](#prompting-images)
  + [Technical details (images)](#technical-details-image)
* [Capabilities](#capabilities)
  + [Get a bounding box for an object](#bbox)
* [Prompting with video](#prompting-video)
  + [Technical details (video)](#technical-details-video)
  + [Upload a video file using the File API](#upload-video)
  + [Verify file upload and check state](#verify-file)
  + [Prompt with a video and text](#prompt-video)
  + [Refer to timestamps in the content](#refer-timestamps)
  + [Transcribe video and provide visual descriptions](#transcribe-video)
* [List files](#list-files)
* [Delete files](#delete-files)
* [What's next](#whats-next)


Python
Node.js
Go
REST


| [View on ai.google.dev](https://ai.google.dev/gemini-api/docs/vision) | [Try a Colab notebook](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/vision.ipynb) | [View notebook on GitHub](https://github.com/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/vision.ipynb) |
| --- | --- | --- |

Gemini models are able to process images and videos, enabling many frontier
developer use cases that would have historically required domain specific models.
Some of Gemini's vision capabilities include the ability to:


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
* [Overview](/gemini-api/docs)
* Get started
* [Quickstart](/gemini-api/docs/quickstart)
* [API keys](/gemini-api/docs/api-key)
* Libraries
  + [Install](/gemini-api/docs/downloads)
  + [Python SDK upgrade](/gemini-api/docs/migrate)
* [Pricing](/gemini-api/docs/pricing)
* [Release notes](/gemini-api/docs/changelog)
* [Developer forum](https://discuss.ai.google.dev/c/gemini-api/)
* Models
* [Gemini](/gemini-api/docs/models/gemini)
* [Experimental models](/gemini-api/docs/models/experimental-models)
* Capabilities
* [Text generation](/gemini-api/docs/text-generation)
* [Vision](/gemini-api/docs/vision)
* [Audio understanding](/gemini-api/docs/audio)
* [Long context](/gemini-api/docs/long-context)
* [Code execution](/gemini-api/docs/code-execution)
* [Structured output](/gemini-api/docs/structured-output)
* [Thinking](/gemini-api/docs/thinking)
* [Multimodal Live API](/api/multimodal-live)
* Image generation
  + [Imagen generation](/gemini-api/docs/imagen)
  + [Imagen prompt guide](/gemini-api/docs/imagen-prompt-guide)
* Function calling
  + [Intro to function calling](/gemini-api/docs/function-calling)
  + [Function calling tutorial](/gemini-api/docs/function-calling/tutorial)
  + [Extract structured data](/gemini-api/tutorials/extract_structured_data)
* [Document understanding](/gemini-api/docs/document-processing)
* Grounding with Google Search
  + [Grounding tutorial](/gemini-api/docs/grounding)
  + [Use Google Search Suggestions](/gemini-api/docs/grounding/search-suggestions)
* Fine-tuning
  + [Intro to fine-tuning](/gemini-api/docs/model-tuning)
  + [Fine-tuning tutorial](/gemini-api/docs/model-tuning/tutorial)
* [Embeddings](/gemini-api/docs/embeddings)
* Guides
* [Multimodal Live API](/gemini-api/docs/multimodal-live)
* [Context caching](/gemini-api/docs/caching)
* Prompt engineering
  + [Intro to prompting](/gemini-api/docs/prompting-intro)
  + [Prompting strategies](/gemini-api/docs/prompting-strategies)
  + [File prompting strategies](/gemini-api/docs/file-prompting-strategies)
* [Token counting](/gemini-api/docs/tokens)
* [OpenAI compatibility](/gemini-api/docs/openai)
* [Rate limits](/gemini-api/docs/rate-limits)
* [Billing info](/gemini-api/docs/billing)
* Safety
  + [Safety settings](/gemini-api/docs/safety-settings)
  + [Safety guidance](/gemini-api/docs/safety-guidance)
* Additional resources
  + [Android (on-device)](/gemini-api/docs/get-started/android_aicore)
  + [Firebase extensions](/gemini-api/docs/firebase-extensions)
  + [Generative models](/gemini-api/docs/models/generative-models)
  + [Google AI Studio quickstart](/gemini-api/docs/ai-studio-quickstart)
  + [LearnLM](/gemini-api/docs/learnlm)
  + [Migrate to Cloud](/gemini-api/docs/migrate-to-cloud)
  + [OAuth authentication](/gemini-api/docs/oauth)
* Gemini for Research
* [Gemini Academic Program](/gemini-api/docs/gemini-for-research)
* Use cases
* Applications
  + [Chat application](/gemini-api/tutorials/web-app)
  + [Code assistant](/gemini-api/tutorials/pipet-code-agent)
  + [Flutter code generator](/gemini-api/tutorials/flutter-theme-agent)
  + [Content search](/gemini-api/tutorials/docs-agent)
  + [Data exploration agent](/gemini-api/tutorials/sql-talk)
  + [Writing assistant](/gemini-api/tutorials/wordcraft)
  + [Slides reviewer](/gemini-api/tutorials/slides-advisor)
* Troubleshooting
* [API troubleshooting](/gemini-api/docs/troubleshooting)
* [AI Studio troubleshooting](/gemini-api/docs/troubleshoot-ai-studio)
* [Google Workspace](/gemini-api/docs/workspace)
* Legal
* [Terms of service](/gemini-api/terms)
* [Available regions](/gemini-api/docs/available-regions)
* [Abuse monitoring](/gemini-api/docs/abuse-monitoring)


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video
The page at `https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video` is likely a part of the documentation for Google's Gemini API, specifically focusing on the vision capabilities. The section titled "prompting-video" suggests that it covers how to use the API to work with video data in the context of vision tasks, using Python as the programming language. It may include examples and instructions on how to prompt the API to process or analyze video content.

Chunk Content:
404  |  Page Not Found  |  Google AI for Developers


[Skip to main content](#main-content)

ai.google.dev uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. [Learn more](https://policies.google.com/technologies/cookies?hl=en).

Hide

[![Google AI for Developers](https://ai.google.dev/_static/googledevai/images/lockup-new.svg)](/)


Models

* Gemini
* [About](https://deepmind.google/gemini)
* [Docs](https://ai.google.dev/gemini-api/docs)
* [API reference](https://ai.google.dev/api)
* [Pricing](https://ai.google.dev/pricing)

* Gemma
* [About](https://ai.google.dev/gemma)
* [Docs](https://ai.google.dev/gemma/docs)


Solutions

* Build with Gemini
* [Gemini API](https://ai.google.dev/gemini-api/docs)
* [Google AI Studio](https://aistudio.google.com)

* Customize Gemma open models
* [Gemma open models](https://ai.google.dev/gemma)
* [Multi-framework with Keras](https://keras.io/keras_3/)
* [Fine-tune in Colab](https://colab.sandbox.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb)

* Run on-device
* [Google AI Edge](https://ai.google.dev/edge)
* [Gemini Nano on Android](https://developer.android.com/ai/gemini-nano)
* [Chrome built-in web APIs](https://developer.chrome.com/docs/ai/built-in)

* Build responsibly
* [Responsible GenAI Toolkit](https://ai.google.dev/responsible)
* [Secure AI Framework](https://saif.google)


Code assistance


URL: https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video
The page at `https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video` is likely a part of the documentation for Google's Gemini API, specifically focusing on the vision capabilities. The section titled "prompting-video" suggests that it covers how to use the API to work with video data in the context of vision tasks, using Python as the programming language. It may include examples and instructions on how to prompt the API to process or analyze video content.

Chunk Content:
* [Gemini Showcase](/showcase)
* [Gemini API Developer Competition](/competition)

* [Google AI Forum](https://discuss.ai.google.dev)
* [Gemini for Research](/gemini-api/docs/gemini-for-research)


### 404

Sorry, we couldn't find that page.


`/`

* [Terms](//policies.google.com/terms)
* [Privacy](//policies.google.com/privacy)
* [Manage cookies](#)


URL: https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
Was this helpful?
Send feedback


Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). For details, see the [Google Developers Site Policies](https://developers.google.com/site-policies). Java is a registered trademark of Oracle and/or its affiliates.

Last updated 2025-02-05 UTC.

Need to tell us more?

[[["Easy to understand","easyToUnderstand","thumb-up"],["Solved my problem","solvedMyProblem","thumb-up"],["Other","otherUp","thumb-up"]],[["Missing the information I need","missingTheInformationINeed","thumb-down"],["Too complicated / too many steps","tooComplicatedTooManySteps","thumb-down"],["Out of date","outOfDate","thumb-down"],["Samples / code issue","samplesCodeIssue","thumb-down"],["Other","otherDown","thumb-down"]],["Last updated 2025-02-05 UTC."],[],[]]


* [Terms](//policies.google.com/terms)
* [Privacy](//policies.google.com/privacy)
* [Manage cookies](#)


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video
The page at the URL you provided, `https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video`, is likely a documentation page related to Google's Gemini API, specifically its vision capabilities. The section `#prompting-video` indicates that this part of the documentation covers how to use the vision API to interact with or analyze video content. Since the parameter `?lang=python` is included in the URL, the examples or instructions are probably given in Python. Overall, this page would be useful for developers looking to understand how to implement video processing or analysis using Google's Gemini API in their Python projects.

Chunk Content:
```

Note that these inline data calls don't include many of the features available
through the File API, such as getting file metadata,
[listing](https://ai.google.dev/gemini-api/docs/vision?lang=python#list-files),
or [deleting files](https://ai.google.dev/gemini-api/docs/vision?lang=python#delete-files).

### Large image payloads

When the combination of files and system instructions that you intend to send is
larger than 20 MB in size, use the File API to upload those files.

Use the [`media.upload`](https://ai.google.dev/api/rest/v1beta/media/upload)
method of the File API to upload an image of any size.

**Note:** The File API lets you store up to 20 GB of files per project, with a
per-file maximum size of 2 GB. Files are stored for 48 hours. They can be
accessed in that period with your API key, but cannot be downloaded from the
API. It is available at no cost in all regions where the Gemini API is
available.

After uploading the file, you can make `GenerateContent` requests that reference
the File API URI. Select the generative model and provide it with a text prompt
and the uploaded image.

```
from google import genai

client = genai.Client(api_key="GEMINI_API_KEY")

img_path = "/path/to/Cajun_instruments.jpg"
file_ref = client.files.upload(path=img_path)
print(f'{file_ref=}')

client = genai.Client(api_key="GEMINI_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=["What can you tell me about these instruments?",
              file_ref])

print(response.text)

```
### OpenAI Compatibility

You can access Gemini's image understanding capabilities using the
OpenAI libraries. This lets you integrate Gemini into existing
OpenAI workflows by updating three lines of code and using
your Gemini API key. See the [Image understanding example](https://ai.google.dev/gemini-api/docs/openai#image-understanding)
for code demonstrating how to send images encoded as Base64 payloads.


URL: https://ai.google.dev/gemini-api/docs/vision?lang=python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video
The page at `https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video` is likely a part of the documentation for Google's Gemini API, specifically focusing on the vision capabilities. The section titled "prompting-video" suggests that it covers how to use the API to work with video data in the context of vision tasks, using Python as the programming language. It may include examples and instructions on how to prompt the API to process or analyze video content.

Chunk Content:
* [English](https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video)
* [Deutsch](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=de#prompting-video)
* [Español – América Latina](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=es-419#prompting-video)
* [Français](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=fr#prompting-video)
* [Indonesia](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=id#prompting-video)
* [Italiano](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=it#prompting-video)
* [Polski](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=pl#prompting-video)
* [Português – Brasil](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=pt-br#prompting-video)
* [Shqip](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=sq#prompting-video)
* [Tiếng Việt](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=vi#prompting-video)
* [Türkçe](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=tr#prompting-video)
* [Русский](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ru#prompting-video)
* [עברית](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=he#prompting-video)
* [العربيّة](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ar#prompting-video)
* [فارسی](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=fa#prompting-video)
* [हिंदी](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=hi#prompting-video)
* [বাংলা](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=bn#prompting-video)
* [ภาษาไทย](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=th#prompting-video)
* [中文 – 简体](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=zh-cn#prompting-video)
* [中文 – 繁體](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=zh-tw#prompting-video)
* [日本語](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ja#prompting-video)
* [한국어](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ko#prompting-video)


URL: https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video

Page Context: 
https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video
The page at `https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video` is likely a part of the documentation for Google's Gemini API, specifically focusing on the vision capabilities. The section titled "prompting-video" suggests that it covers how to use the API to work with video data in the context of vision tasks, using Python as the programming language. It may include examples and instructions on how to prompt the API to process or analyze video content.

Chunk Content:
* [English](https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video)
* [Deutsch](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=de#prompting-video)
* [Español – América Latina](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=es-419#prompting-video)
* [Français](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=fr#prompting-video)
* [Indonesia](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=id#prompting-video)
* [Italiano](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=it#prompting-video)
* [Polski](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=pl#prompting-video)
* [Português – Brasil](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=pt-br#prompting-video)
* [Shqip](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=sq#prompting-video)
* [Tiếng Việt](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=vi#prompting-video)
* [Türkçe](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=tr#prompting-video)
* [Русский](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ru#prompting-video)
* [עברית](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=he#prompting-video)
* [العربيّة](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ar#prompting-video)
* [فارسی](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=fa#prompting-video)
* [हिंदी](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=hi#prompting-video)
* [বাংলা](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=bn#prompting-video)
* [ภาษาไทย](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=th#prompting-video)
* [中文 – 简体](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=zh-cn#prompting-video)
* [中文 – 繁體](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=zh-tw#prompting-video)
* [日本語](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ja#prompting-video)
* [한국어](https://ai.google.dev/gemini-api/docs/vision/lang/python?hl=ko#prompting-video)


URL: https://ai.google.dev/gemini-api/docs/vision/lang/python#prompting-video

